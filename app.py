# import necessary libraries
#---------------------------------------------------------------------------------
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
from PIL import Image
import os
from dotenv import load_dotenv

# load_dotenv()

genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])


output_dir = "saliency_maps"
os.makedirs(output_dir, exist_ok = True)

#Create load_function for Xception model
# ----------------------------------------------------------------------------------------
def load_xception_model(model_path):
  img_shape = (299,299,3)
  base_model = tf.keras.applications.Xception(include_top=False, weights="imagenet", input_shape= img_shape, pooling= "max")

  model= Sequential(
      [base_model,
       Flatten(),
       Dropout( rate=0.3),
       Dense(128, activation="relu"),
       Dropout(rate=0.25),
       Dense(4, activation="softmax")]
  )

  model.build((None,) + img_shape)

  #compile the model
  model.compile(Adamax(learning_rate=0.001),
                loss="categorical_crossentropy",
                metrics=["accuracy", Precision(), Recall()])

  model.load_weights(model_path)

  return model


# Create saliency map function
# ---------------------------------------------------------------------------
def generate_saliency_map(model, img_array, class_index, img_size):
  with tf.GradientTape() as tape:
    img_tensor = tf.convert_to_tensor(img_array)
    tape.watch(img_tensor)
    predictions = model(img_tensor)
    target_class = predictions[:, class_index]

  gradients = tape.gradient(target_class, img_tensor)
  gradients = tf.math.abs(gradients)
  gradients = tf.reduce_mean(tf.abs(gradients), axis=-1).numpy().squeeze()

  # Resize gradients to match oroginal image size
  gradients = cv2.resize(gradients, img_size)

  # Create a circular mask for the brain
  center = (gradients.shape[0] // 2, gradients.shape[1]//2)
  radius = min(center[0], center[1]) - 10
  y,x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
  mask = (x-center[0])**2  + (y - center[1])**2 <= radius**2

  # Apply mask to the gradients
  gradients = gradients * mask

  # Normalize only the brain area
  brain_gradients = gradients[mask]

  if brain_gradients.size > 0:
        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
  gradients[mask] = brain_gradients        

  # Apply threshold (experiment with lower thresholds)
  threshold = np.percentile(gradients[mask], 60)  # Lower the percentile to include more data
  gradients[gradients < threshold] = 0

  # Apply more aggresive smoothing
  gradients = cv2.GaussianBlur(gradients, (15,15), 0)

  # Create a heatmap overlay with enhanced contrast
  heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
  heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)

  #Resize the heatmap to match the original image size
  heatmap = cv2.resize(heatmap, img_size)

  # Superimpose the heatmap on original image with increased opacity
  original_img = image.img_to_array(img)
  superimposed_img = heatmap * 0.7 + original_img * 0.3
  superimposed_img = superimposed_img.astype(np.uint8)

  img_path = os.path.join(output_dir, uploaded_file.name)
  with open(img_path, "wb") as f:
    f.write(uploaded_file.getbuffer())

  saliency_map_path = f"saliency_maps/{uploaded_file.name}"

  # Save the saliency map
  cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

  return superimposed_img


# Create function to generate explanation
# --------------------------------------------------------------------------------
def generate_explanation(img_path, model_prediction, confidence, expert):
    # Define the prompt based on the selected expert
    if expert == "Neurologist":
        prompt = f"""
        You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.
        The saliency map was generated by a deep learning model that was trained to classify brain tumors as either glioma, meningioma, pituitary, or no tumor.

        The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100:.2f}%.
        
        Provide your response in **bullet points**:
        - Identify the regions of the brain the model is focusing on, based on the saliency map.
        - Explain the possible neural implications of the highlighted areas.
        - Suggest the necessary diagnostic tests or imaging to confirm the diagnosis.
        - Recommend treatment options for class '{model_prediction}'.
        - Outline a follow-up plan, including timelines for monitoring progress and reevaluating the condition.
        - Collaborate with other specialists as needed, and describe their potential roles in the treatment process.
        """

    elif expert == "Radiologist":
        prompt = f"""
        You are an expert radiologist. You are tasked with interpreting a saliency map of a brain MRI scan.
        The saliency map highlights regions used by a deep learning model trained to classify brain tumors into glioma, meningioma, pituitary, or no tumor.

        The model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100:.2f}%.
        
        Provide your response in **bullet points**:
        - Describe the anatomical regions highlighted in the saliency map and their radiological significance.
        - Correlate the highlighted regions with typical tumor patterns for '{model_prediction}'.
        - Recommend additional imaging (e.g., contrast MRI or CT scans) or diagnostic procedures.
        - Identify potential areas of concern requiring further investigation.
        - Advise on how to share findings with other medical professionals for collaborative care.
        - Suggest an appropriate timeline for follow-up imaging or diagnostics.
        """

    elif expert == "Oncologist":
        prompt = f"""
        You are an expert oncologist specializing in brain tumors. You are tasked with analyzing a saliency map of a brain MRI scan.
        The saliency map was created by a deep learning model trained to classify brain tumors as glioma, meningioma, pituitary, or no tumor.

        The model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100:.2f}%.
        
        Provide your response in **bullet points**:
        - Highlight the implications of the saliency map for cancer diagnosis and prognosis.
        - Recommend immediate next steps for the patient (e.g., biopsy, genetic testing, blood work).
        - Outline treatment strategies tailored to '{model_prediction}' (e.g., surgery, chemotherapy, radiotherapy).
        - Include recommendations for supportive care or symptom management.
        - Provide a timeline for reevaluation and follow-up treatments.
        - Suggest collaboration with neurosurgeons, radiologists, or other specialists as necessary.
        """

    else:
        prompt = "Invalid expert selection. Please select a valid expert."

    # Load the image
    img = Image.open(img_path)

    # Initialize and call the generative model (using OpenAI's hypothetical API)
    model = genai.GenerativeModel(model_name="gemini-1.5-flash")
    response = model.generate_content([prompt, img])

    return response.text


# Create function to generate summary
# --------------------------------------------------------------------------------
def generate_summary(explanation):
   prompt = f"""
    Based on the provided {explanation}, summarize the key points in bullet format. The summary should:
    - Clearly convey the main ideas from the explanation.
    - Include any actionable next steps.
    - Be concise and easy to read."""
   model = genai.GenerativeModel(model_name="gemini-1.5-flash")
   response = model.generate_content([prompt])
   return response.text
   


# Create function for chatbot
# --------------------------------------------------------------------------------   
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # Initialize chat history in session state

def get_chatbot_response(question, saliency_map, prediction_class, confidence):
   system_prompt = f"""
   You are a medical AI assistant specializing in brain MRI scans. A user has uploaded a brain MRI image and its corresponding saliency map.
    The deep learning model predicted the image to be of class '{prediction_class}' with a confidence of {confidence * 100:.2f}%.

        User: {question}

    """
   # Load the image
   img = Image.open(saliency_map)
   
   model = genai.GenerativeModel(model_name="gemini-1.5-flash")
   try:
      response = model.generate_content([system_prompt, img])
      return response.text
   except Exception as e:
      return f"An error occurred: {e}"









# Set the title of the app
# The front end section
# --------------------------------------------------------------------------------
st.title("Brain Tumor Classification")
st.write("Upload an MRI image to classify the tumor type.")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:

  selected_model = st.radio("Select a model:", ["Transfer Learning - Xception", "Custom CNN"])

  if selected_model == "Transfer Learning - Xception":
    model = load_xception_model("xception_model.weights.h5")
    img_size = (299,299)
  else:
    model = load_model("cnn_model.h5")
    img_size = (224,224)

  labels = ["Glioma", "Meningioma", "No tumor", "Pituitary"]
  img = image.load_img(uploaded_file, target_size=img_size)
  img_array = image.img_to_array(img)
  img_array = np.expand_dims(img_array, axis=0)
  img_array /= 255.0

  prediction = model.predict(img_array)

  #Get the class with the highest probabibility
  class_index = np.argmax(prediction[0])
  result = labels[class_index]

  # Display the predicted class inside a blue box
  st.markdown(f"""
    <div style="background-color: rgba(0, 123, 255, 0.3); color: black; padding: 20px; border-radius: 10px; text-align: center; font-size: 24px; margin-bottom: 30px;">
        Predicted Class: {result}
    </div>
""", unsafe_allow_html=True)

  # st.write(f"Predicted Class: {result}")
  # st.write("Predictions")
  # for label, prob in zip(labels, prediction[0]):
  #   st.write(f"{label}: {prob:.4f}")



  # Create a dictionary for the labels and probabilities
  predictions = {label: prob for label, prob in zip(labels, prediction[0])}
  # create bar plot for the predictions
  fig = go.Figure(go.Bar(
      x = list(predictions.values()),
      y = list(predictions.keys()),
      orientation = "h",
      marker=dict(
            color='skyblue',  # color for bars
            line=dict(color='darkblue', width=1.5)),
      text=[f"{prob:.2%}" for prob in predictions.values()],  # format as percentage
      textposition='auto'  # display annotations inside bars
      ))

  # Customize layout
  fig.update_layout(
              title="Prediction Probabilities",
              xaxis=dict(title="Probability"),
              yaxis=dict(title="Tumor Type"),
              template="plotly_white"
    )

  st.plotly_chart(fig)


  saliency_map = generate_saliency_map(model, img_array, class_index, img_size)

  col1, col2 = st.columns(2)

  with col1:
    st.image(uploaded_file, caption = "Uploaded Image",  use_container_width = True)
  with col2:
    st.image(saliency_map, caption= "Saliency Map",  use_container_width=True)




  st.write("## Explanation")
  expert = st.selectbox("Select an expert:", ["Neurologist", "Radiologist", "Oncologist"])

  

  saliency_map_path = f"saliency_maps/{uploaded_file.name}"
  explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index], expert)
  
  # Explanation section based on expert. Has to choose the expert first in order to see the explanation
  if expert:
     st.write(explanation)

     # Add a summary section below the explanation
     st.write("## Summary")
     summary_text = generate_summary(explanation)
     st.write(summary_text)
        

  st.write("## Ask the Chatbot")

  # Display chat messages
  for message in st.session_state.chat_history:
     with st.chat_message(message["role"]):
        st.write(message["content"])

# Chat input
  user_input = st.chat_input("Ask about the MRI analysis...")

  # Process user input
  if user_input:
     # Display user message immediately
     with st.chat_message("user"):
        st.markdown(user_input)
     
     # Get and display AI response
     with st.chat_message("assistant"):
        with st.spinner("Thinking..."):        
                ai_response = get_chatbot_response(user_input, saliency_map_path, result, prediction[0][class_index])
                st.markdown(ai_response)

   
     # Add messages to history after displaying them
     st.session_state.chat_history.append({"role": "user", "content": user_input})
     st.session_state.chat_history.append({"role": "assistant", "content": ai_response})

    

  

